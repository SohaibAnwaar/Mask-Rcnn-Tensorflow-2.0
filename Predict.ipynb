{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# Set CPU as available physical device\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import shutil\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "\n",
    "DIR_TO_SAVE = \"./TestMarkerResults/\"\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "\n",
    "class GenericConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, classes, steps):\n",
    "        self.NUM_CLASSES = classes +1\n",
    "        self.STEPS_PER_EPOCH = steps\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "    NAME = \"class\"\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.1\n",
    "    IMAGE_MAX_DIM=448\n",
    "    IMAGE_MIN_DIM=384\n",
    "    TRAIN_ROIS_PER_IMAGE=20\n",
    "    DETECTION_NMS_THRESHOLD=0.1\n",
    "    DETECTION_MAX_INSTANCES=10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "\n",
    "\n",
    "def predict(model, image_path, labels):\n",
    "    \n",
    "    print(f\"labels {labels}\")\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = np.array(image)\n",
    "    \n",
    "    results = model.detect([image], verbose=0)\n",
    "\n",
    "    r = results[0]\n",
    "    classes = [\"background\"]\n",
    "    classes += labels\n",
    "\n",
    "    \n",
    "    out = display_instances(image,r['rois'],r['masks'],r['class_ids'],classes,r['scores'])\n",
    "    plt.imshow(out)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "def random_colors(N):\n",
    "    np.random.seed(1)\n",
    "    colors = [tuple(255 * np.random.rand(3)) for _ in range(N)]\n",
    "    return colors\n",
    "\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"apply mask to image\"\"\"\n",
    "    for n, c in enumerate(color):\n",
    "        image[:, :, n] = np.where(\n",
    "            mask == 1,\n",
    "            image[:, :, n] * (1 - alpha) + alpha * c,\n",
    "            image[:, :, n]\n",
    "        )\n",
    "    return image\n",
    "\n",
    "\n",
    "def display_instances(image, boxes, masks, ids, names, scores):\n",
    "    \"\"\"\n",
    "        take the image and results and apply the mask, box, and Label\n",
    "    \"\"\"\n",
    "    n_instances = boxes.shape[0]\n",
    "    colors = random_colors(n_instances)\n",
    "\n",
    "    if not n_instances:\n",
    "        print('NO INSTANCES TO DISPLAY')\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
    "\n",
    "    for i, color in enumerate(colors):\n",
    "        if not np.any(boxes[i]):\n",
    "            continue\n",
    "\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        label = names[ids[i]]\n",
    "        score = scores[i] if scores is not None else None\n",
    "        caption = '{} {:.2f}'.format(label, score) if score else label\n",
    "        mask = masks[:, :, i]\n",
    "\n",
    "        image = apply_mask(image, mask, color)\n",
    "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        image = cv2.putText(\n",
    "            image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
    "        )\n",
    "        plt.imsave(f\"/media/sohaib/additional_/DataScience/OCR/mrcnn_results/{int(random.random()*10000)}.jpg\", image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "weights_path = \"mask_rcnn_448_class_0701.h5\"\n",
    "MODEL_DIR = \"/\".join(weights_path.split(\"/\")[:-2])\n",
    "config = GenericConfig(7,100)\n",
    "config.display()\n",
    "\n",
    "# Create model in inference mode\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,config=config)\n",
    "\n",
    "model.load_weights(weights_path, by_name=True)  \n",
    "print(\"Weights loaded\")\n",
    "    \n",
    "\n",
    "images = [file for file in glob.glob(\"/media/sohaib/additional_/DataScience/MaskRCNN/maskrcnn2_0/images/test/*.*g\")]\n",
    "print(len(images))\n",
    "\n",
    "\n",
    "labels = [\"car_producer\",\"license_plate\",\"car_model\",\"date\",\"address\",\"last_name\",\"first_name\"]\n",
    "\n",
    "for image in images:\n",
    "    \n",
    "    predict(model, image, labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
