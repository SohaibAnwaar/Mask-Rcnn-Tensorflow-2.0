{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import shutil\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "\n",
    "DIR_TO_SAVE = \"./TestMarkerResults/\"\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Configurations\n",
    "############################################################\n",
    "\n",
    "\n",
    "class GenericConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, classes, steps):\n",
    "        self.NUM_CLASSES = classes\n",
    "        self.STEPS_PER_EPOCH = steps\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"class\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 1\n",
    "    GPU_COUNT = 1\n",
    "\n",
    "\n",
    "\n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.99\n",
    "    IMAGE_MAX_DIM=448\n",
    "    IMAGE_MIN_DIM=384\n",
    "    TRAIN_ROIS_PER_IMAGE=20\n",
    "    DETECTION_NMS_THRESHOLD=0.1\n",
    "    DETECTION_MAX_INSTANCES=25\n",
    "#     RPN_ANCHOR_SCALES = (32, 64, 128, 256,512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "\n",
    "\n",
    "def predict(model, image_path, labels):\n",
    "    \n",
    "    print(f\"labels {labels}\")\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = np.array(image)\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    classes = [\"background\"]\n",
    "    classes += labels\n",
    "    \n",
    "    visualize.save_image(image,image_path.split(\"/\")[-1],r['rois'],None,r['class_ids'],r['scores'],classes,save_dir=\"/Users/fahadali/Downloads/BallTest/BallResults/\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_colors(N):\n",
    "    np.random.seed(1)\n",
    "    colors = [tuple(255 * np.random.rand(3)) for _ in range(N)]\n",
    "    return colors\n",
    "\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"apply mask to image\"\"\"\n",
    "    for n, c in enumerate(color):\n",
    "        image[:, :, n] = np.where(\n",
    "            mask == 1,\n",
    "            image[:, :, n] * (1 - alpha) + alpha * c,\n",
    "            image[:, :, n]\n",
    "        )\n",
    "    return image\n",
    "\n",
    "\n",
    "def display_instances(image, boxes, masks, ids, names, scores):\n",
    "    \"\"\"\n",
    "        take the image and results and apply the mask, box, and Label\n",
    "    \"\"\"\n",
    "    n_instances = boxes.shape[0]\n",
    "    colors = random_colors(n_instances)\n",
    "\n",
    "    if not n_instances:\n",
    "        print('NO INSTANCES TO DISPLAY')\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
    "\n",
    "    for i, color in enumerate(colors):\n",
    "        if not np.any(boxes[i]):\n",
    "            continue\n",
    "\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        label = names[ids[i]]\n",
    "        score = scores[i] if scores is not None else None\n",
    "        caption = '{} {:.2f}'.format(label, score) if score else label\n",
    "        mask = masks[:, :, i]\n",
    "\n",
    "        image = apply_mask(image, mask, color)\n",
    "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        image = cv2.putText(\n",
    "            image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
    "        )\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "weights_path = \"\"\n",
    "MODEL_DIR = \"/\".join(weights_path.split(\"/\")[:-2])\n",
    "config = GenericConfig(2,1000)\n",
    "config.display()\n",
    "\n",
    "# Create model in inference mode\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,config=config)\n",
    "\n",
    "model.load_weights(weights_path, by_name=True)  \n",
    "print(\"Weights loaded\")\n",
    "    \n",
    "\n",
    "images = [file for file in glob.glob(\"\")]\n",
    "\n",
    "print(len(images))\n",
    "\n",
    "\n",
    "labels = ['Marker']\n",
    "\n",
    "for image in images:\n",
    "    predict(model, image, labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob \n",
    "\n",
    "batch_size = 1\n",
    "weights_path = \"\"\n",
    "MODEL_DIR = \"/\".join(weights_path.split(\"/\")[:-2])\n",
    "config = GenericConfig(81,1000)\n",
    "\n",
    "config.display()\n",
    "\n",
    "# Create model in inference mode\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,config=config)\n",
    "\n",
    "model.load_weights(weights_path)  \n",
    "\n",
    "print(\"Weights loaded\")\n",
    "\n",
    "\n",
    "class_names = [\n",
    "        'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "        'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "        'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "        'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "        'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "        'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "        'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "        'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "        'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "        'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "        'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "        'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "        'teddy bear', 'hair drier', 'toothbrush'\n",
    "    ]\n",
    "\n",
    "\n",
    "capture = cv2.VideoCapture(\"/Users/fahadali/Downloads/1.mp4\")\n",
    "\n",
    "\n",
    "frames = []\n",
    "frame_count = 0\n",
    "\n",
    "\n",
    "images = [file for file in glob.glob(\"\")]\n",
    "print(len(images))\n",
    "\n",
    "for image in images:\n",
    "    predict(model, image, class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
