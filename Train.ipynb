{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for gpu_instance in physical_devices: \n",
    "    tf.config.experimental.set_memory_growth(gpu_instance, True)\n",
    "\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "set_session(sess)\n",
    "from PIL import Image    \n",
    "import os, glob\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import visualize as vis\n",
    "from mrcnn import model as modellib, utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class GenericDataset(utils.Dataset):\n",
    "\n",
    "    def load_item(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of dataset.\n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "        annotations = json.load(open(os.path.join(dataset_dir, \"via_region_data.json\")))\n",
    "        annotations = list(annotations.values())  # don't need the dict keys\n",
    "\n",
    "\n",
    "\n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "        \n",
    "        # Add images\n",
    "        classes = []\n",
    "\n",
    "        all_files = dict()\n",
    "        for _ in os.listdir(dataset_dir):\n",
    "            all_files[\".\".join(_.split(\".\")[:-1])] = _ \n",
    "        for a in annotations:\n",
    "\n",
    "            polygons=[]\n",
    "            objects=[]\n",
    "            for r in a['regions']:\n",
    "                polygons.append(r['shape_attributes'])\n",
    "                objects.append(r['region_attributes'])\n",
    "\n",
    "            class_ids = [int(n['class']) for n in objects]\n",
    "            image_path = dataset_dir + \"/\" + all_files[a['filename'] ]\n",
    "            image = Image.open(image_path)\n",
    "            width, height = image.size\n",
    "\n",
    "            self.add_image(\n",
    "                \"class\",\n",
    "                image_id=a['filename'],  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                polygons=polygons,\n",
    "                class_ids=class_ids)\n",
    "\n",
    "            for r in a['regions']:\n",
    "\n",
    "                _class = r['region_attributes']['class']\n",
    "                if _class not in classes:\n",
    "                    classes += [_class]\n",
    "\n",
    "        for i in range(len(classes)):\n",
    "            self.add_class(\"class\", i+1,  str(_class))\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a dataset image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"class\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "        class_ids = image_info['class_ids']\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "\n",
    "        class_ids = np.array(class_ids, dtype=np.int32)\n",
    "        return mask, class_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Build Dataset.\"\"\"\n",
    "print(\"Loading Training Dataset...\")\n",
    "DATASET_DIR = \"/media/sohaib/additional_/maskrcnn2_0/images/train/\"\n",
    "\n",
    "# Training dataset.\n",
    "dataset_train = GenericDataset()\n",
    "dataset_train.load_item(DATASET_DIR, \"train\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "print(\"Loading Validation Dataset...\")\n",
    "dataset_val = GenericDataset()\n",
    "dataset_val.load_item(DATASET_DIR, \"val\")\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "count = 0\n",
    "rows, cols      = 2, 2\n",
    "class_ids = list(dataset_val.class_ids)\n",
    "ids_list  = random.sample(class_ids[0:500], rows * cols)\n",
    "\n",
    "for id_ in ids_list: \n",
    "    count += 1\n",
    "    id_ -= 1\n",
    "    \n",
    "    image = dataset_val.load_image(id_)\n",
    "    mask, class_id= dataset_val.load_mask(id_)\n",
    "    _, _, masks_num = mask.shape\n",
    "    # Ploting Masks\n",
    "    for i in range(masks_num):\n",
    "        mask_ = vis.apply_mask(image, mask[:,:,i], [1,2,3])\n",
    "    \n",
    "    plt.subplot(rows, cols, count)\n",
    "    plt.imshow(mask_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.config import Config\n",
    "WEIGHTS_DIR = \"/media/sohaib/additional_/maskrcnn/weights/\"\n",
    "\n",
    "class GenericConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, classes, steps):\n",
    "        self.NUM_CLASSES = classes + 1\n",
    "        self.STEPS_PER_EPOCH = steps\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "    NAME = \"class\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    DETECTION_MIN_CONFIDENCE = 0.1\n",
    "    IMAGE_MAX_DIM=448\n",
    "    IMAGE_MIN_DIM=384\n",
    "    TRAIN_ROIS_PER_IMAGE=20\n",
    "    DETECTION_NMS_THRESHOLD=0.1\n",
    "    DETECTION_MAX_INSTANCES=10\n",
    "\n",
    "\n",
    "config = GenericConfig(7, 100)\n",
    "\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=WEIGHTS_DIR)\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "transfer_weights_path = \"/media/sohaib/additional_/maskrcnn/weights/448_class20210419T0158/mask_rcnn_448_class_0171.h5\"\n",
    "model.load_weights(transfer_weights_path, by_name=False, exclude=None)\n",
    "\n",
    "model.train(dataset_train, dataset_val,\n",
    "        learning_rate=config.LEARNING_RATE,\n",
    "        epochs=1000,\n",
    "        layers='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
